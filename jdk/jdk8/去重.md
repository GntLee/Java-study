> list去重

```java
@Test
    public void distinct() {
        PageData pd1 = new PageData();
        pd1.put("id", 1);
        pd1.put("subject", "语文");

        PageData pd2 = new PageData();
        pd2.put("id", 2);
        pd2.put("subject", "数学");

        PageData pd3 = new PageData();
        pd3.put("id", 2);
        pd3.put("subject", "数学");

        List<PageData> list = Arrays.asList(pd1, pd2, pd3);
        System.out.println(list);

        long start = System.currentTimeMillis();
        // 方式一
        ArrayList<PageData> list2 = list.stream().collect(Collectors.collectingAndThen(Collectors.toCollection(() -> new TreeSet<>(Comparator.comparing(o -> o.getString("subject")))), ArrayList::new));
        System.out.println(list2);
        System.out.println(System.currentTimeMillis() - start);

        // 方式二
        long start1 = System.currentTimeMillis();
        List<PageData> datas = list.stream().filter(distinctByKey(o -> (Integer)o.get("id"))).collect(Collectors.toList());
        System.out.println(datas);
        System.out.println(System.currentTimeMillis() - start1);

    }

    //自定义根据对象属性过滤重复的对象
    private <T> Predicate<T> distinctByKey(Function<? super T, Object> keyExtractor) {
        Map<Object, Boolean> seen = new ConcurrentHashMap<>();
        return t -> seen.putIfAbsent(keyExtractor.apply(t), Boolean.TRUE) == null;
    }
```
